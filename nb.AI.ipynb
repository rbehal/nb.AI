{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRawData(year):\n",
    "\n",
    "    # URL page we will scraping (see image above)\n",
    "    url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\".format(year)\n",
    "    # this is the HTML from the given URL\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    # use findALL() to get the column headers\n",
    "    soup.findAll('tr', limit=2)\n",
    "    # use getText()to extract the text we need into a list\n",
    "    headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "    # exclude the first column as we will not need the ranking order from Basketball Reference for the analysis\n",
    "    headers = headers[1:]\n",
    "\n",
    "    # avoid the first header row\n",
    "    rows = soup.findAll('tr')[1:]\n",
    "    player_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                for i in range(len(rows))]\n",
    "    \n",
    "    stats = pd.DataFrame(player_stats, columns = headers)\n",
    "    stats = stats.drop('Pos', axis=1)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(stats):\n",
    "    # Deleting duplicates\n",
    "    stats.drop_duplicates(subset='Player', keep='first',inplace=True)\n",
    "    \n",
    "    stats.set_index(\"Player\",inplace=True) # Player is index value\n",
    "\n",
    "    # Dropping unrelated values/unknowns\n",
    "    stats.drop('Tm', 1, inplace=True)\n",
    "    stats.dropna(inplace=True)\n",
    "\n",
    "    # One hot encoding player position\n",
    "#     stats = pd.get_dummies(stats, columns=['Pos'])\n",
    "\n",
    "\n",
    "    # Checking for autocorrelation and dropping those columns\n",
    "    stats = stats.apply(pd.to_numeric)\n",
    "    corr = stats.corr()\n",
    "\n",
    "    threshold = 0.90\n",
    "\n",
    "    columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i+1, corr.shape[0]):\n",
    "            if corr.iloc[i,j] >= threshold:\n",
    "                if columns[j]:\n",
    "                    columns[j] = False\n",
    "    \n",
    "    selected_columns = stats.columns[columns]\n",
    "    stats = stats[selected_columns]\n",
    "\n",
    "    # Standardizing feature dataset\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(stats)\n",
    "    x_scaled = scaler.transform(stats)\n",
    "    stats_x = pd.DataFrame(x_scaled, columns = stats.columns)\n",
    "    \n",
    "#     stats_x = stats_x.iloc[:, :12]\n",
    "\n",
    "    # Replacing NAN values after standardization\n",
    "    stats_x = stats_x.fillna(0)\n",
    "\n",
    "    # Concatenating standardized data with one hot encoded data\n",
    "#     pos_stats = stats.iloc[:,11:]\n",
    "#     pos_stats.reset_index(inplace = True)\n",
    "#     pos_stats.drop('Player', 1, inplace=True)\n",
    "    \n",
    "    #print(\"POS STATS: \", pos_stats, \"STATS_X\", stats_x)\n",
    "\n",
    "#     pp_data = pd.concat([stats_x,pos_stats],axis=1) # Final preprocessed data\n",
    "    \n",
    "    return stats_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTarget():\n",
    "    mvp = []\n",
    "    for i in range(530):\n",
    "        if i == 18:\n",
    "            mvp.append(1)\n",
    "        else :\n",
    "            mvp.append(0)\n",
    "    mvp_df = pd.DataFrame(mvp)\n",
    "    mvp_df = mvp_df.rename(columns={0:\"MVP\"})\n",
    "    return mvp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_2018 = createRawData(2018)\n",
    "stats_2019 = createRawData(2019)\n",
    "pp_2018 = preprocessData(stats_2018)\n",
    "pp_2019 = preprocessData(stats_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pp_2019\n",
    "y = addTarget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\New folder\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lr.predict_proba(pp_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 0.9994793832110053 at index 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(540, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ = 0\n",
    "index = None\n",
    "arr = results[:,0]\n",
    "for i in range(0, arr.size):\n",
    "    if (arr[i] > max_):\n",
    "        max_ = arr[i]\n",
    "        index = i\n",
    "print(\"Maximum value: {} at index {}\".format(max_, index))\n",
    "results[:,1][index]\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age        30\n",
       "G           1\n",
       "GS          0\n",
       "MP        5.0\n",
       "FG        1.0\n",
       "FGA       1.0\n",
       "FG%     1.000\n",
       "3P        0.0\n",
       "3PA       0.0\n",
       "3P%          \n",
       "2P        1.0\n",
       "2PA       1.0\n",
       "2P%     1.000\n",
       "eFG%    1.000\n",
       "FT        0.0\n",
       "FTA       0.0\n",
       "FT%          \n",
       "ORB       1.0\n",
       "DRB       0.0\n",
       "TRB       1.0\n",
       "AST       0.0\n",
       "STL       0.0\n",
       "BLK       0.0\n",
       "TOV       1.0\n",
       "PF        1.0\n",
       "PTS       2.0\n",
       "Name: Jeremy Evans, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_2018.iloc[150,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 2)\n",
      "(540, 26)\n"
     ]
    }
   ],
   "source": [
    "print(results.shape)\n",
    "print(stats_2018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#               'alpha': (1e-1,1e-2, 1e-3,1e-4,1),\n",
    "#               'max_iter': (10,100,1000),\n",
    "#               'penalty': ('l2', 'l1', 'elasticnet') \n",
    "#              }\n",
    "# gs_clf = GridSearchCV(SGDClassifier(), parameters, n_jobs=-1, verbose=10)\n",
    "# gs_clf = gs_clf.fit(X,y)\n",
    "# print(gs_clf.best_score_)\n",
    "# print(gs_clf.best_params_)\n",
    "#lr = LogisticRegression()\n",
    "#lr.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
